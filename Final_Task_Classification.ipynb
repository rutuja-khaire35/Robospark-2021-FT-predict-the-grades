{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Task_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mks-XkJdKK5V"
      },
      "source": [
        "\n",
        "#                                                     **Predict the Student Grades**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5yaYUmGhKHB"
      },
      "source": [
        "DRIVE ACCESS AUTHENTICATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEGuVR2i9qUJ",
        "outputId": "f954757d-efe6-451b-92f6-63fab944f448"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7-0lIkrhdBa"
      },
      "source": [
        "IMPORTING PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8TM2ClVk7qk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i0msnvXhhGr"
      },
      "source": [
        "READING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHIQS2kX9xSS"
      },
      "source": [
        "path = '/content/drive/MyDrive/Untitled folder/Task/student-por.csv' \n",
        "df = pd.read_csv(path,sep=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVYvY-0OhkiK"
      },
      "source": [
        "DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "lotr8d-gjQSa",
        "outputId": "bddb3d6e-ce8c-4f70-86f3-78b59502ab2a"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>at_home</td>\n",
              "      <td>teacher</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>health</td>\n",
              "      <td>services</td>\n",
              "      <td>home</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>home</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>MS</td>\n",
              "      <td>F</td>\n",
              "      <td>19</td>\n",
              "      <td>R</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>services</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>MS</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>teacher</td>\n",
              "      <td>services</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>MS</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>647</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>services</td>\n",
              "      <td>services</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>648</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>18</td>\n",
              "      <td>R</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>services</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>649 rows Ã— 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    school sex  age address famsize Pstatus  ...  Walc  health absences  G1  G2  G3\n",
              "0       GP   F   18       U     GT3       A  ...     1       3        4   0  11  11\n",
              "1       GP   F   17       U     GT3       T  ...     1       3        2   9  11  11\n",
              "2       GP   F   15       U     LE3       T  ...     3       3        6  12  13  12\n",
              "3       GP   F   15       U     GT3       T  ...     1       5        0  14  14  14\n",
              "4       GP   F   16       U     GT3       T  ...     2       5        0  11  13  13\n",
              "..     ...  ..  ...     ...     ...     ...  ...   ...     ...      ...  ..  ..  ..\n",
              "644     MS   F   19       R     GT3       T  ...     2       5        4  10  11  10\n",
              "645     MS   F   18       U     LE3       T  ...     1       1        4  15  15  16\n",
              "646     MS   F   18       U     GT3       T  ...     1       5        6  11  12   9\n",
              "647     MS   M   17       U     LE3       T  ...     4       2        6  10  10  10\n",
              "648     MS   M   18       R     LE3       T  ...     4       5        4  10  11  11\n",
              "\n",
              "[649 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "pWLrvfHxlASH",
        "outputId": "afaeb437-18b2-4632-e6f6-acad3fc3c583"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>at_home</td>\n",
              "      <td>teacher</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>health</td>\n",
              "      <td>services</td>\n",
              "      <td>home</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>home</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school sex  age address famsize Pstatus  ...  Walc  health absences  G1  G2  G3\n",
              "0     GP   F   18       U     GT3       A  ...     1       3        4   0  11  11\n",
              "1     GP   F   17       U     GT3       T  ...     1       3        2   9  11  11\n",
              "2     GP   F   15       U     LE3       T  ...     3       3        6  12  13  12\n",
              "3     GP   F   15       U     GT3       T  ...     1       5        0  14  14  14\n",
              "4     GP   F   16       U     GT3       T  ...     2       5        0  11  13  13\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNhdr8imhpf_",
        "outputId": "e8527144-abce-4af1-c6b2-2204b01ec4ed"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(649, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apJNM7HE866s",
        "outputId": "4e2c0523-e28c-41f5-8612-4e9bfb962d06"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
              "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
              "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
              "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
              "       'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXXJzxwM8_m-",
        "outputId": "802ce046-8bae-4955-a3c6-775309bf7ffc"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 649 entries, 0 to 648\n",
            "Data columns (total 33 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   school      649 non-null    object\n",
            " 1   sex         649 non-null    object\n",
            " 2   age         649 non-null    int64 \n",
            " 3   address     649 non-null    object\n",
            " 4   famsize     649 non-null    object\n",
            " 5   Pstatus     649 non-null    object\n",
            " 6   Medu        649 non-null    int64 \n",
            " 7   Fedu        649 non-null    int64 \n",
            " 8   Mjob        649 non-null    object\n",
            " 9   Fjob        649 non-null    object\n",
            " 10  reason      649 non-null    object\n",
            " 11  guardian    649 non-null    object\n",
            " 12  traveltime  649 non-null    int64 \n",
            " 13  studytime   649 non-null    int64 \n",
            " 14  failures    649 non-null    int64 \n",
            " 15  schoolsup   649 non-null    object\n",
            " 16  famsup      649 non-null    object\n",
            " 17  paid        649 non-null    object\n",
            " 18  activities  649 non-null    object\n",
            " 19  nursery     649 non-null    object\n",
            " 20  higher      649 non-null    object\n",
            " 21  internet    649 non-null    object\n",
            " 22  romantic    649 non-null    object\n",
            " 23  famrel      649 non-null    int64 \n",
            " 24  freetime    649 non-null    int64 \n",
            " 25  goout       649 non-null    int64 \n",
            " 26  Dalc        649 non-null    int64 \n",
            " 27  Walc        649 non-null    int64 \n",
            " 28  health      649 non-null    int64 \n",
            " 29  absences    649 non-null    int64 \n",
            " 30  G1          649 non-null    int64 \n",
            " 31  G2          649 non-null    int64 \n",
            " 32  G3          649 non-null    int64 \n",
            "dtypes: int64(16), object(17)\n",
            "memory usage: 167.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "IIomTU5B_Iex",
        "outputId": "1cf1b624-414b-4e7f-f125-2d9589559761"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>16.744222</td>\n",
              "      <td>2.514638</td>\n",
              "      <td>2.306626</td>\n",
              "      <td>1.568567</td>\n",
              "      <td>1.930663</td>\n",
              "      <td>0.221880</td>\n",
              "      <td>3.930663</td>\n",
              "      <td>3.180277</td>\n",
              "      <td>3.184900</td>\n",
              "      <td>1.502311</td>\n",
              "      <td>2.280431</td>\n",
              "      <td>3.536210</td>\n",
              "      <td>3.659476</td>\n",
              "      <td>11.399076</td>\n",
              "      <td>11.570108</td>\n",
              "      <td>11.906009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.218138</td>\n",
              "      <td>1.134552</td>\n",
              "      <td>1.099931</td>\n",
              "      <td>0.748660</td>\n",
              "      <td>0.829510</td>\n",
              "      <td>0.593235</td>\n",
              "      <td>0.955717</td>\n",
              "      <td>1.051093</td>\n",
              "      <td>1.175766</td>\n",
              "      <td>0.924834</td>\n",
              "      <td>1.284380</td>\n",
              "      <td>1.446259</td>\n",
              "      <td>4.640759</td>\n",
              "      <td>2.745265</td>\n",
              "      <td>2.913639</td>\n",
              "      <td>3.230656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age        Medu        Fedu  ...          G1          G2          G3\n",
              "count  649.000000  649.000000  649.000000  ...  649.000000  649.000000  649.000000\n",
              "mean    16.744222    2.514638    2.306626  ...   11.399076   11.570108   11.906009\n",
              "std      1.218138    1.134552    1.099931  ...    2.745265    2.913639    3.230656\n",
              "min     15.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     16.000000    2.000000    1.000000  ...   10.000000   10.000000   10.000000\n",
              "50%     17.000000    2.000000    2.000000  ...   11.000000   11.000000   12.000000\n",
              "75%     18.000000    4.000000    3.000000  ...   13.000000   13.000000   14.000000\n",
              "max     22.000000    4.000000    4.000000  ...   19.000000   19.000000   19.000000\n",
              "\n",
              "[8 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "7tDj4GyG6JyF",
        "outputId": "b4860755-a818-49ff-f38a-09256064e79f"
      },
      "source": [
        "df.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.107832</td>\n",
              "      <td>-0.121050</td>\n",
              "      <td>0.034490</td>\n",
              "      <td>-0.008415</td>\n",
              "      <td>0.319968</td>\n",
              "      <td>-0.020559</td>\n",
              "      <td>-0.004910</td>\n",
              "      <td>0.112805</td>\n",
              "      <td>0.134768</td>\n",
              "      <td>0.086357</td>\n",
              "      <td>-0.008750</td>\n",
              "      <td>0.149998</td>\n",
              "      <td>-0.174322</td>\n",
              "      <td>-0.107119</td>\n",
              "      <td>-0.106505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Medu</th>\n",
              "      <td>-0.107832</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.647477</td>\n",
              "      <td>-0.265079</td>\n",
              "      <td>0.097006</td>\n",
              "      <td>-0.172210</td>\n",
              "      <td>0.024421</td>\n",
              "      <td>-0.019686</td>\n",
              "      <td>0.009536</td>\n",
              "      <td>-0.007018</td>\n",
              "      <td>-0.019766</td>\n",
              "      <td>0.004614</td>\n",
              "      <td>-0.008577</td>\n",
              "      <td>0.260472</td>\n",
              "      <td>0.264035</td>\n",
              "      <td>0.240151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fedu</th>\n",
              "      <td>-0.121050</td>\n",
              "      <td>0.647477</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.208288</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>-0.165915</td>\n",
              "      <td>0.020256</td>\n",
              "      <td>0.006841</td>\n",
              "      <td>0.027690</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.038445</td>\n",
              "      <td>0.044910</td>\n",
              "      <td>0.029859</td>\n",
              "      <td>0.217501</td>\n",
              "      <td>0.225139</td>\n",
              "      <td>0.211800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traveltime</th>\n",
              "      <td>0.034490</td>\n",
              "      <td>-0.265079</td>\n",
              "      <td>-0.208288</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.063154</td>\n",
              "      <td>0.097730</td>\n",
              "      <td>-0.009521</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>0.057454</td>\n",
              "      <td>0.092824</td>\n",
              "      <td>0.057007</td>\n",
              "      <td>-0.048261</td>\n",
              "      <td>-0.008149</td>\n",
              "      <td>-0.154120</td>\n",
              "      <td>-0.154489</td>\n",
              "      <td>-0.127173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>studytime</th>\n",
              "      <td>-0.008415</td>\n",
              "      <td>0.097006</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>-0.063154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.147441</td>\n",
              "      <td>-0.004127</td>\n",
              "      <td>-0.068829</td>\n",
              "      <td>-0.075442</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>-0.214925</td>\n",
              "      <td>-0.056433</td>\n",
              "      <td>-0.118389</td>\n",
              "      <td>0.260875</td>\n",
              "      <td>0.240498</td>\n",
              "      <td>0.249789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>failures</th>\n",
              "      <td>0.319968</td>\n",
              "      <td>-0.172210</td>\n",
              "      <td>-0.165915</td>\n",
              "      <td>0.097730</td>\n",
              "      <td>-0.147441</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.062645</td>\n",
              "      <td>0.108995</td>\n",
              "      <td>0.045078</td>\n",
              "      <td>0.105949</td>\n",
              "      <td>0.082266</td>\n",
              "      <td>0.035588</td>\n",
              "      <td>0.122779</td>\n",
              "      <td>-0.384210</td>\n",
              "      <td>-0.385782</td>\n",
              "      <td>-0.393316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>famrel</th>\n",
              "      <td>-0.020559</td>\n",
              "      <td>0.024421</td>\n",
              "      <td>0.020256</td>\n",
              "      <td>-0.009521</td>\n",
              "      <td>-0.004127</td>\n",
              "      <td>-0.062645</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.129216</td>\n",
              "      <td>0.089707</td>\n",
              "      <td>-0.075767</td>\n",
              "      <td>-0.093511</td>\n",
              "      <td>0.109559</td>\n",
              "      <td>-0.089534</td>\n",
              "      <td>0.048795</td>\n",
              "      <td>0.089588</td>\n",
              "      <td>0.063361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freetime</th>\n",
              "      <td>-0.004910</td>\n",
              "      <td>-0.019686</td>\n",
              "      <td>0.006841</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>-0.068829</td>\n",
              "      <td>0.108995</td>\n",
              "      <td>0.129216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.346352</td>\n",
              "      <td>0.109904</td>\n",
              "      <td>0.120244</td>\n",
              "      <td>0.084526</td>\n",
              "      <td>-0.018716</td>\n",
              "      <td>-0.094497</td>\n",
              "      <td>-0.106678</td>\n",
              "      <td>-0.122705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goout</th>\n",
              "      <td>0.112805</td>\n",
              "      <td>0.009536</td>\n",
              "      <td>0.027690</td>\n",
              "      <td>0.057454</td>\n",
              "      <td>-0.075442</td>\n",
              "      <td>0.045078</td>\n",
              "      <td>0.089707</td>\n",
              "      <td>0.346352</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.245126</td>\n",
              "      <td>0.388680</td>\n",
              "      <td>-0.015741</td>\n",
              "      <td>0.085374</td>\n",
              "      <td>-0.074053</td>\n",
              "      <td>-0.079469</td>\n",
              "      <td>-0.087641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dalc</th>\n",
              "      <td>0.134768</td>\n",
              "      <td>-0.007018</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.092824</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>0.105949</td>\n",
              "      <td>-0.075767</td>\n",
              "      <td>0.109904</td>\n",
              "      <td>0.245126</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.616561</td>\n",
              "      <td>0.059067</td>\n",
              "      <td>0.172952</td>\n",
              "      <td>-0.195171</td>\n",
              "      <td>-0.189480</td>\n",
              "      <td>-0.204719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Walc</th>\n",
              "      <td>0.086357</td>\n",
              "      <td>-0.019766</td>\n",
              "      <td>0.038445</td>\n",
              "      <td>0.057007</td>\n",
              "      <td>-0.214925</td>\n",
              "      <td>0.082266</td>\n",
              "      <td>-0.093511</td>\n",
              "      <td>0.120244</td>\n",
              "      <td>0.388680</td>\n",
              "      <td>0.616561</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.114988</td>\n",
              "      <td>0.156373</td>\n",
              "      <td>-0.155649</td>\n",
              "      <td>-0.164852</td>\n",
              "      <td>-0.176619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health</th>\n",
              "      <td>-0.008750</td>\n",
              "      <td>0.004614</td>\n",
              "      <td>0.044910</td>\n",
              "      <td>-0.048261</td>\n",
              "      <td>-0.056433</td>\n",
              "      <td>0.035588</td>\n",
              "      <td>0.109559</td>\n",
              "      <td>0.084526</td>\n",
              "      <td>-0.015741</td>\n",
              "      <td>0.059067</td>\n",
              "      <td>0.114988</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.030235</td>\n",
              "      <td>-0.051647</td>\n",
              "      <td>-0.082179</td>\n",
              "      <td>-0.098851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absences</th>\n",
              "      <td>0.149998</td>\n",
              "      <td>-0.008577</td>\n",
              "      <td>0.029859</td>\n",
              "      <td>-0.008149</td>\n",
              "      <td>-0.118389</td>\n",
              "      <td>0.122779</td>\n",
              "      <td>-0.089534</td>\n",
              "      <td>-0.018716</td>\n",
              "      <td>0.085374</td>\n",
              "      <td>0.172952</td>\n",
              "      <td>0.156373</td>\n",
              "      <td>-0.030235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.147149</td>\n",
              "      <td>-0.124745</td>\n",
              "      <td>-0.091379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G1</th>\n",
              "      <td>-0.174322</td>\n",
              "      <td>0.260472</td>\n",
              "      <td>0.217501</td>\n",
              "      <td>-0.154120</td>\n",
              "      <td>0.260875</td>\n",
              "      <td>-0.384210</td>\n",
              "      <td>0.048795</td>\n",
              "      <td>-0.094497</td>\n",
              "      <td>-0.074053</td>\n",
              "      <td>-0.195171</td>\n",
              "      <td>-0.155649</td>\n",
              "      <td>-0.051647</td>\n",
              "      <td>-0.147149</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.864982</td>\n",
              "      <td>0.826387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G2</th>\n",
              "      <td>-0.107119</td>\n",
              "      <td>0.264035</td>\n",
              "      <td>0.225139</td>\n",
              "      <td>-0.154489</td>\n",
              "      <td>0.240498</td>\n",
              "      <td>-0.385782</td>\n",
              "      <td>0.089588</td>\n",
              "      <td>-0.106678</td>\n",
              "      <td>-0.079469</td>\n",
              "      <td>-0.189480</td>\n",
              "      <td>-0.164852</td>\n",
              "      <td>-0.082179</td>\n",
              "      <td>-0.124745</td>\n",
              "      <td>0.864982</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.918548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G3</th>\n",
              "      <td>-0.106505</td>\n",
              "      <td>0.240151</td>\n",
              "      <td>0.211800</td>\n",
              "      <td>-0.127173</td>\n",
              "      <td>0.249789</td>\n",
              "      <td>-0.393316</td>\n",
              "      <td>0.063361</td>\n",
              "      <td>-0.122705</td>\n",
              "      <td>-0.087641</td>\n",
              "      <td>-0.204719</td>\n",
              "      <td>-0.176619</td>\n",
              "      <td>-0.098851</td>\n",
              "      <td>-0.091379</td>\n",
              "      <td>0.826387</td>\n",
              "      <td>0.918548</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 age      Medu      Fedu  ...        G1        G2        G3\n",
              "age         1.000000 -0.107832 -0.121050  ... -0.174322 -0.107119 -0.106505\n",
              "Medu       -0.107832  1.000000  0.647477  ...  0.260472  0.264035  0.240151\n",
              "Fedu       -0.121050  0.647477  1.000000  ...  0.217501  0.225139  0.211800\n",
              "traveltime  0.034490 -0.265079 -0.208288  ... -0.154120 -0.154489 -0.127173\n",
              "studytime  -0.008415  0.097006  0.050400  ...  0.260875  0.240498  0.249789\n",
              "failures    0.319968 -0.172210 -0.165915  ... -0.384210 -0.385782 -0.393316\n",
              "famrel     -0.020559  0.024421  0.020256  ...  0.048795  0.089588  0.063361\n",
              "freetime   -0.004910 -0.019686  0.006841  ... -0.094497 -0.106678 -0.122705\n",
              "goout       0.112805  0.009536  0.027690  ... -0.074053 -0.079469 -0.087641\n",
              "Dalc        0.134768 -0.007018  0.000061  ... -0.195171 -0.189480 -0.204719\n",
              "Walc        0.086357 -0.019766  0.038445  ... -0.155649 -0.164852 -0.176619\n",
              "health     -0.008750  0.004614  0.044910  ... -0.051647 -0.082179 -0.098851\n",
              "absences    0.149998 -0.008577  0.029859  ... -0.147149 -0.124745 -0.091379\n",
              "G1         -0.174322  0.260472  0.217501  ...  1.000000  0.864982  0.826387\n",
              "G2         -0.107119  0.264035  0.225139  ...  0.864982  1.000000  0.918548\n",
              "G3         -0.106505  0.240151  0.211800  ...  0.826387  0.918548  1.000000\n",
              "\n",
              "[16 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOmOuF0OezSP"
      },
      "source": [
        "Count Plot of G3 , So the Maximum Value of G3 is 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "bgCWp0KGexl_",
        "outputId": "927d5c16-9484-436b-f536-e43bd9de8183"
      },
      "source": [
        "df['G3'].value_counts().plot(kind=\"bar\",color=['g']);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65eeWM2_LI6j"
      },
      "source": [
        "Count Plot Between G3 and School\n",
        "So, We can see GP school students have higher G3 Scores as compared to MS school Students"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "vFBKh9OKjEF3",
        "outputId": "3eee3fdd-9fbe-4eca-bc4e-45d17d84d7e0"
      },
      "source": [
        "# count plot on single categorical variable\n",
        "sns.countplot(x ='school',hue='G3', data = df) \n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAFDCAYAAAA9PmWPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3SV9Z3v8fc3Jogw9YKEEIkYLGAgASIyImc60MKAoKByERppi4Klx1NnqEertM6sSq0jWC1ejx0UK9YKKpcGHKpgBMVVrYBCtWCwAgrIXRAFEQPf80c2DtBkZ0P3sx/I7/NaKyv7uey9P7qSL7/8nt/z3ebuiIhIOLLiDiAiIpmlwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoHJjjuASJSWLl3aLDs7+1GghBNvoHMAeKeqquraCy64YEvcYaT+UOGXei07O/vR5s2bt8vNzd2RlZV1Qt20cuDAAdu6dWv7TZs2PQpcFnceqT9OtBGQyNEqyc3N3XWiFX2ArKwsz83N/YTqv1ZE0kaFX+q7rBOx6B+UyK7fU0kr/UCJpGjdunXZAwYMaFVQUNChuLi4XWlpadETTzxx+oIFCxoVFRW1Lyoqan/eeee1f+KJJ06PO6tIMprjF0nBgQMHGDBgQOurrrpq+5w5c9YArFq1qsGzzz57+sCBA3e9/fbbK3Jycvjggw9yzj///PZlZWU7c3Jy4o4tUiMVfpEUzJkz52s5OTl+8803bz24r23btvtuvfXWw1bbfP7552ZmmQ8ochQ01SOSgrfffvuUjh077qnt+EsvvdS4devWxZ07dy6eOHHiBxrty/FMhV/kGHz3u99ted5557UvKSlpB9CzZ8/df/3rX//y6quvrvzlL3+Zv2fPHg375bilwi+Sgg4dOnz+5z//udHB7d/+9rcfLly4cNWOHTsOmy7t3Lnz3saNG+9fsmTJKZlPKZIaFX6RFAwYMODTL774wiZMmJB7cN9nn32WBfDuu+82+PLLL4HqC76rV69u2KZNm30xRRWpky7uiqQgKyuLOXPmvP/DH/7w7Pvvv795kyZNqho1arT/tttuW19RUfEP/fv3z8/OzvasrCy/5557PszPz6+KO7NIbUwfvSj12fLly9d26tRpW9w5/h7Lly9v2qlTp8K4c0j9oakeEZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFIjZ9+vRTCwsLS1q2bFny05/+tHnceUR0A5cEZevDT16QztfLve47S5Mdr6qq4oYbbmj5wgsvrDr33HO/7NSpU7vBgwfvvOCCC/amM4fI0dCIXyRCCxcubHzOOed80b59+30NGzb0QYMGfTx9+nR9UIvESoVfJELr1q1r0KJFi6/69hQUFOzbsGFDgzgziajwi4gERoVfJEJnn332YSP89evXH/YXgEgcVPhFItSjR4/da9eubfjuu+822Lt3r82cObPJ4MGDd8adS8KmVT0iEcrJyeGee+75sG/fvm3379/PVVddta1Lly5a0SOxUltmqdfUllnkb2mqR0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+kYhdeeWVhU2aNOnUpk2b4riziIBu4JLAbPx/t6a1LXP+/7kjaVtmgJEjR24bM2bMlmuuuaZVOt9b5FhpxC8SsX79+n2Wm5tbFXcOkYNU+EVEAqPCLyISGBV+EZHAqPCLiARGhV8kYgMGDGj1jW98o2jNmjUn5+XldZw4cWLTuDNJ2LScU4KSyvLLdJszZ86aTL+nSDIa8YuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPlnCIZ0KJFiw6NGzfen5WVRXZ2tr/zzjsr484k4VLhl6C89esBaW3LfP7/npPyfQEvv/zyqvz8fHXplNhpqkdEJDAq/CIZ0qtXrzbFxcXt7r77brVskFhpqkckA1599dV3W7Vq9eWGDRuye/bs2ba4uHhvv379Pos7l4RJI36RDGjVqtWXAC1atKi69NJLd7722muN484k4VLhF4nYrl27snbs2JF18PGCBQtO7dix4+dx55JwaapHJGLr16/PHjhwYGuA/fv32+DBg7cPGTJkV9y5JFwq/BKUo1l+mS7t27ffV1lZuSLT7ytSG031iIgERoVfRCQwJ8RUT9OmTb2wsDDuGHICuuuuu1ixYsU5cef4e2zfvp0uXbp43DnkxLN06dJt7p575P4TovAXFhayZMmSuGPICWjlypW0a9cu7hh/FzPTz78cEzP7oKb9muoREQmMCr+ISGBU+EUyYOfOnQwZMoSioiLatWvHa6+9FnckCdgJMccvki5zJ1+S1te7ZNTclM4bM2YMffv2Zfr06ezbt489e/akNYfI0VDhF4nYJ598wiuvvMLjjz8OQIMGDWjQoEG8oSRokU31mNl5ZrbskK9dZvYjM2tiZvPN7L3E9zOiyiByPFizZg25ublcc801nH/++Vx77bXs3r077lgSsMgKv7tXunupu5cCFwB7gFnAWKDC3dsAFYltkXqrqqqKN998k+uuu4633nqLxo0bM378+LhjScAydXG3F/C+u38AXA5MSeyfAlyRoQwisSgoKKCgoICuXbsCMGTIEN58882YU0nIMlX4vw1MTTzOc/eNicebgLwMZRCJRfPmzTn77LOprKwEoKKigvbt28ecSkIW+cVdM2sAXAb85Mhj7u5mVuOt6GY2GhgN0LJly0gz1nf9Z0yu9dhzg0dlMEm4HnjgAYYPH86+ffs499xz+c1vfhN3JAlYJlb19APedPfNie3NZpbv7hvNLB/YUtOT3H0SMAlQnxJJm1SXX6ZbaWmp2i7IcSMTUz1l/M80D8BsYETi8QigPAMZREQkIdLCb2aNgd7AzEN2jwd6m9l7wL8ktkVEJEMinepx993AmUfs2071Kh8REYmBevWIiARGhV9EJDAq/CIigVHhF4lYZWUlpaWlX32deuqp3HvvvXHHkoCpO6ckNXDGgqTHZw3+VoaSpMdjU/qk9fVGjphX5znnnXcey5YtA2D//v20aNGCgQMHpjWHyNHQiF8kgyoqKvj617/OOeec0J//Lic4FX6RDJo2bRplZWVxx5DAqfCLZMi+ffuYPXs2V155ZdxRJHAq/CIZ8oc//IHOnTuTl6eGtBIvFX6RDJk6daqmeeS4oMIvkgG7d+9m/vz5DBo0KO4oIlrOKWFJZfllFBo3bsz27dtjeW+RI2nELyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/SMQmTpxIcXExJSUllJWVsXfv3rgjSeC0jl+C8ounL07r6/37sBeSHt+wYQP3338/K1as4JRTTmHo0KFMmzaNq6++Oq05RI6GRvwiEauqquLzzz+nqqqKPXv2cNZZZ8UdSQIXaeE3s9PNbLqZvWtmK82sm5k1MbP5ZvZe4vsZUWYQiVOLFi246aabaNmyJfn5+Zx22mn06ZPeD4MROVpRj/jvA5539yKgE7ASGAtUuHsboCKxLVIv7dixg/LyctasWcNHH33E7t27efLJJ+OOJYGLrPCb2WlAd2AygLvvc/edwOXAlMRpU4ArosogErcXX3yRVq1akZubS05ODoMGDeKPf/xj3LEkcFGO+FsBW4HfmNlbZvaomTUG8tx9Y+KcTUCNzcnNbLSZLTGzJVu3bo0wpkh0WrZsyeuvv86ePXtwdyoqKmjXrl3csSRwURb+bKAz8LC7nw/s5ohpHXd3wGt6srtPcvcu7t4lNzc3wpgi0enatStDhgyhc+fOdOjQgQMHDjB69Oi4Y0ngolzOuR5Y7+5/SmxPp7rwbzazfHffaGb5wJYIM4gcpq7ll1EYN24c48aNy/j7itQmshG/u28C1pnZeYldvYAVwGxgRGLfCKA8qgwiIvK3or6B61+B35lZA2A1cA3V/9g8Y2ajgA+AoRFnEBGRQ0Ra+N19GdClhkO9onxfERGpne7cFREJjAq/iEhgVPhFRAKjwi8Ssfvuu4+SkhKKi4u59957444jorbMEpZ+5WVpfb0/XD416fF33nmHRx55hDfeeIMGDRrQt29f+vfvT+vWrdOaQ+RoaMQvEqGVK1fStWtXGjVqRHZ2Nj169GDmzJlxx5LAqfCLRKikpIRFixaxfft29uzZw9y5c1m3bl3csSRwmuoRiVC7du245ZZb6NOnD40bN6a0tJSTTjop7lgSOI34RSI2atQoli5dyiuvvMIZZ5xB27Zt444kgdOIP3ADps9IejzbmmQoSf21ZcsWmjVrxocffsjMmTN5/fXX444kgVPhF4nY4MGD2b59Ozk5OTz00EOcfvrpcUeSwKnwS1DqWn4ZhUWLFmX8PUWS0Ry/iEhgVPhFRAKjwi8iEhjN8dcDl8yakPR4Fk0zlERETgQa8YuIBEaFX0QkMCr8IhEbOXIkzZo1o6Sk5Kt9H3/8Mb1796ZNmzb07t2bHTt2xJhQQqM5fglKXddDjtbcgbfUec7VV1/N9ddfz/e+972v9o0fP55evXoxduxYxo8fz/jx45kwIb3ZRGoT6YjfzNaa2dtmtszMliT2NTGz+Wb2XuL7GVFmEIlb9+7dadLk8NYX5eXljBgxAoARI0bw+9//Po5oEqhMTPV8y91L3b1LYnssUOHubYCKxLZIUDZv3kx+fj4AzZs3Z/PmzTEnkpDEMcd/OTAl8XgKcEUMGUSOG2aGmcUdQwISdeF3YJ6ZLTWz0Yl9ee6+MfF4E5AXcQaR405eXh4bN1b/GmzcuJFmzZrFnEhCEnXh/4a7dwb6AT80s+6HHnR3p/ofh79hZqPNbImZLdm6dWvEMUUy67LLLmPKlOo/fKdMmcLll18ecyIJSaSF3903JL5vAWYBFwKbzSwfIPF9Sy3PneTuXdy9S25ubpQxRSJVVlZGt27dqKyspKCggMmTJzN27Fjmz59PmzZtePHFFxk7Vpe6JHMiW85pZo2BLHf/NPG4D/BzYDYwAhif+F4eVQaRI6Wy/DLdpk6tuRV0RUVFhpOIVItyHX8eMCtx0SobeMrdnzezxcAzZjYK+AAYGmEGERE5QmSF391XA51q2L8d6BXV+4qISHJq2SAiEhgVfhGRwKjwi4gERoVfRCQwKvwiEaupLfOzzz5LcXExWVlZLFmyJMZ0EiK1ZZag9J8xOa2v99zgUXWeU1Nb5pKSEmbOnMkPfvCDtOYRSYUKv0jEunfvztq1aw/b165du3jCiKDCL3+nYTNWJT3+9OC2GUoiIqnSHL+ISGBU+EVEAqPCLyISGBV+kYjV1JZ51qxZFBQU8Nprr3HppZdy8cUXxx1TAqKLuxKUVJZfplttbZkHDhyY4SQi1VT4RSQyl8yakPR4HJ+PIJrqEREJjgq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi0SsprbMP/7xjykqKqJjx44MHDiQnTt3xphQQqPlnBKUAdNnpPX15gwZXOc5NbVl7t27N3feeSfZ2dnccsst3HnnnUyYkHzpo0i6RD7iN7OTzOwtM3susd3KzP5kZn81s6fNrEHUGUTi1L17d5o0aXLYvj59+pCdXT3uuuiii1i/fn0c0SRQmRjxjwFWAqcmticAE919mpn9GhgFPJyBHBKDSTO3JD0+elCzDCU5fj322GMMGzYs7hgSkJRG/GZWkcq+Gs4pAC4FHk1sG9ATmJ44ZQpwRaphReqbO+64g+zsbIYPHx53FAlI0hG/mTUEGgFNzewMwBKHTgVapPD69wI3A19LbJ8J7HT3qsT2+tpex8xGA6MBWrZsmcJbiZxYHn/8cZ577jkqKiqoHhOJZEZdUz0/AH4EnAUs5X8K/y7gwWRPNLP+wBZ3X2pm3zzaYO4+CZgE0KVLFz/a54scz55//nnuuusuXn75ZRo1ahR3HAlM0sLv7vcB95nZv7r7A0f52v8EXGZmlwANqf4r4T7gdDPLToz6C4ANx5Bb5IRRVlbGwoUL2bZtGwUFBYwbN44777yTL774gt69ewPVF3h//etfx5xUQpHSxV13f8DM/hdQeOhz3P2JJM/5CfATgMSI/yZ3H25mzwJDgGnACKD8WMOLHK1Ull+mW01tmUeNynx7aJGDUir8ZvZb4OvAMmB/YrcDtRb+JG4BppnZL4C3gMnH8BoiInKMUl3O2QVo7+7HNNfu7guBhYnHq4ELj+V1RETk75fqDVzvAM2jDCIiIpmR6oi/KbDCzN4Avji4090viySViIhEJtXCf1uUIUREJHNSXdXzctRBREQkM1Jt2fCpme1KfO01s/1mtivqcCL1QU1tmf/jP/6Djh07UlpaSp8+ffjoo49iTCihSXXEf7DlwsF+O5cDF0UVSiQqA2csSOvrzRr8rTrPqakt849//GNuv/12AO6//35+/vOf6wYuyZijbsvs1X4PXBxBHpF6p6a2zKeeeupXj3fv3q1ePZJRqd7ANeiQzSyq1/XvjSSRSCBuvfVWnnjiCU477TQWLEjvXyIiyaQ64h9wyNfFwKdUT/eIyDG64447WLduHcOHD+fBB5P2PBRJq1Tn+K+JOohIqIYPH84ll1zCuHHj4o4igUh1VU+Bmc0ysy2JrxmJD1kRkWPw3nvvffW4vLycoqKiGNNIaFK9ges3wFPAlYnt7yT29Y4ilEh9UlNb5rlz51JZWUlWVhbnnHOOVvRIRqVa+HPd/TeHbD9uZj+KIpBIlFJZfpluastcu/4zkjfnfW6w/j9FIdWLu9vN7DtmdlLi6zvA9iiDiYhINFIt/COBocAmYCPVH6RydUSZREQkQqlO9fwcGOHuOwDMrAlwN9X/IIiIyAkk1RF/x4NFH8DdPwbOjyaSiIhEKdXCn2VmZxzcSIz4U/1rQUREjiOpFu97gNcSH5QO1cs674gmkoiIRCmlEb+7PwEMAjYnvga5+2+jDCZSX9TUlvmge+65BzNj27ZtMSSTUKU8XePuK4AVqZ5vZg2BV4CTE+8z3d1/ZmatgGnAmcBS4Lvuvu+oUosco2EzVqX19Z4e3LbOc2pqywywbt065s2bR8uWLdOaSaQuR92W+Sh8AfR0905AKdDXzC4CJgAT3b01sAPQHRpSr9XUlhnghhtu4K677lJLZsm4yAp/om//Z4nNnMSXAz2B6Yn9U4ArosogcrwqLy+nRYsWdOrUKe4oEqBIV+aY2UlUT+e0Bh4C3gd2untV4pT1QIsoM4gcb/bs2cN//ud/Mm/evLijSKCinOrB3fe7eylQAFwIpNyC0MxGm9kSM1uydevWyDKKZNr777/PmjVr6NSpE4WFhaxfv57OnTuzadOmuKNJIDKyFt/dd5rZAqAbcLqZZSdG/QXAhlqeMwmYBNClSxfPRE6RTOjQoQNbtmz5aruwsJAlS5bQtGnTGFNJSCIb8ZtZrpmdnnh8CtUtnFcCC6ju9QMwAiiPKoPI8aCsrIxu3bpRWVlJQUEBkycn70gpErUoR/z5wJTEPH8W8Iy7P2dmK4BpZvYL4C1AvwWSMaksv0y3mtoyH2rt2rWZCSKSEFnhd/c/U0M/H3dfTfV8v4iIxCDSi7siInL8UeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+kYjV1Jb5tttuo0WLFpSWllJaWsrcuXNjTCih0adoSVAmzdxS90lHYfSgZnWeU1tb5htuuIGbbroprXlEUqERv0jEamvLLBIXFX6RmDz44IN07NiRkSNHsmPHjrjjSEBU+EVicN111/H++++zbNky8vPzufHGG+OOJAHRHL/E6qXfJW+53XN4boaSZFZeXt5Xj7///e/Tv3//GNMcu37lZUmPG6UZSiJHQyN+kRhs3Ljxq8ezZs2q8YPYRaKiEb9IxMrKyli4cCHbtm2joKCAcePGsXDhQpYtW4aZUVhYyH/913/FHVMCosIvx7X3Htyc9Hib6/OSHj9SKssv062mtsyjRo3KeA6RgzTVIyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/SMRqassM8MADD1BUVERxcTE333xzTOkkRJGt4zezs4EngDzAgUnufp+ZNQGeBgqBtcBQd1eHKsmIulpEHK1UWkrU1JZ5wYIFlJeXs3z5ck4++WS2bElvu2iRZKK8gasKuNHd3zSzrwFLzWw+cDVQ4e7jzWwsMBa4JcIcIrHq3r07a9euPWzfww8/zNixYzn55JMBaNYs8zeWpeIXT1+c/ISGajd9IopsqsfdN7r7m4nHnwIrgRbA5cCUxGlTgCuiyiByvFq1ahWLFi2ia9eu9OjRg8WLF8cdSQKSkZYNZlYInA/8Cchz94MdqjZRPRUkEpSqqio+/vhjXn/9dRYvXszQoUNZvXo1ZhZ3NAlA5Bd3zewfgBnAj9x916HH3N2pnv+v6XmjzWyJmS3ZujW987IicSsoKGDQoEGYGRdeeCFZWVls27Yt7lgSiEgLv5nlUF30f+fuMxO7N5tZfuJ4PlDjVS13n+TuXdy9S25u/ezJLuG64oorWLBgAVA97bNv3z6aNm0acyoJRWSF36r/Zp0MrHT3Xx1yaDYwIvF4BFAeVQaR40FZWRndunWjsrKSgoICJk+ezMiRI1m9ejUlJSV8+9vfZsqUKZrmkYyJco7/n4DvAm+b2bLEvp8C44FnzGwU8AEwNMIMIoeJ4xO9amrLDPDkk09mOIlItcgKv7u/CtQ2hOkV1fuKiEhyunNXRCQwKvwiIoFR4RcRCYwKv4hIYPRh6yJy3BowfUbS43OGDE56fNiMVbUee3pw22PKVB9oxC8SsZraMg8bNozS0lJKS0spLCyktLQ0xoQSGo34JSjvPbg5ra/X5vq6W03V1Jb56aef/urxjTfeyGmnnZbWXCLJqPCLRKymtswHuTvPPPMML730UmZDSdA01SMSo0WLFpGXl0ebNm3ijiIB0YhfJEZTp06lrKws7hgnrIEzFiQ93oAWGUpyYlHhF4lJVVUVM2fOZOnSpXFHkcBoqkckJi+++CJFRUUUFBTEHUUCoxH/caCuzzX992EvZCiJRKGsrIyFCxeybds2CgoKGDduHKNGjWLatGmUlZXx5ZbtcUeUwKjwS1BSWX6ZbrW1ZX788ccBVPgl4zTVIyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/SMRqasu8bNkyLrroIkpLS7moTy8Wv/lmjAklNJGt4zezx4D+wBZ3L0nsawI8DRQCa4Gh7r4jqgwiR9r0q7+k9fWa/9/iOs+pqS3zzTffzM9+9jP69evH7Kem8ZPbb+PFWbPTmk3+Pi/9bmvS4z2H52YoSfpFOeJ/HOh7xL6xQIW7twEqEtsi9Vr37t1p0qTJYfvMjF27dgHwya5d5Oc1jyOaBCqyEb+7v2JmhUfsvhz4ZuLxFGAhcEtUGUSOV/feey8XX3wxN910Eweqqnj5uT/EHUkCkumWDXnuvjHxeBNQ6/3zZjYaGA3QsmXLDEQ7fvUrT96219DH9p1oHn74YSZOnMjgwYN56pHJ/OCGMTw/fWbcsSQQsV3cdXcHPMnxSe7exd275OaeuHNpIjWZMmUKgwYNAmDIZZez+C1d3JXMyXTh32xm+QCJ71sy/P4ix4WzzjqLl19+GYAFixbR+txzY04kIcn0VM9sYAQwPvG9PMPvL/VMnat0+sW/YrmmtsyPPPIIY8aMoaqqipNPyubhu38Vd0wJSJTLOadSfSG3qZmtB35GdcF/xsxGAR8AQ6N6f5GapLL8Mt1qa8t88JO31JZZMi3KVT21XZHsFdV7iohI3fRBLCISpEkzk19ibI1lKEnmxT8BKiIiGaXCLyISGE31iATssSl9kp/QsP5Od4RMI34RkcCo8ItErKa2zMuXL6dbt2506NCBK75zFbs+/TTGhBIaTfVIULY8UJHW12v2r3WvTq6pLfO1117L3XffTY8ePXjk3vu556EHGTf2J2nNJvGq6+bCOO4pOUgjfpGI1dSWedWqVXTv3h2AXj2+yaz/nhNHNAmUCr9IDIqLiykvr+5YMmNOOes3bIg5kYREUz0iMXjsscf4t3/7N26//XYu7fUvNGjQIO5IcpTee3Bz0uNfy1COY6HCLxKDoqIi5s2bB8BfXvsTf5g/P+ZEEhJN9YjEYMuW6nYBBw4c4M6Jv2L0iKvjDSRBUeEXiVhZWRndunWjsrKSgoICJk+ezNSpU2nbti1FRUXk5zVnRNlVcceUgGiqR4KSyvLLdKutLfOYMWMAtWWWzNOIX0QkMBrxZ4D6oYjI8UQjfhGRwKjwS73n7nFHOGYncnY5fmmqJw3mTr4k+Qn6vxybhg0bsn37ds4880zMTqwpNXdnx2ef0rBhw7ijSD2jkiT1WkFBAevXr2fr1q1xR6nV/k8/q/VYzu69nPuNizKYRkIQS+E3s77AfcBJwKPuPj6OHFL/5eTk0KpVq7hjJLX14SeTHs/51j9nKImEIuOF38xOAh4CegPrgcVmNtvdV0T5vsl+uap8ZdLnbsr6c/IXzzmWRJIJydowx7GmPw5JpyL1N39s6moRHuXPZxwXdy8E/uruq919HzANuDyGHCIiQYqj8LcA1h2yvT6xT0REMsAyvVzMzIYAfd392sT2d4Gu7n79EeeNBkYnNs8DKjMatH5rCmyLO4RIDfSzmV7nuHvukTvjmOHbAJx9yHZBYt9h3H0SMClToUJiZkvcvUvcOUSOpJ/NzIhjqmcx0MbMWplZA+DbwOwYcoiIBCnjI353rzKz64EXqF7O+Zi7J/9UYhERSZtYFnO5+1xgbhzvLYCm0OT4pZ/NDMj4xV0REYmXmrSJiARGhb8eM7M8M3vKzFab2VIze83MBprZN83sEzNbZmYrzexncWeVcJiZm9mTh2xnm9lWM3susZ1nZs+Z2XIzW2FmmhZOMxX+esqqW1H+HnjF3c919wuoXkFVkDhlkbuXAl2A75hZ55iiSnh2AyVmdkpiuzeHL+n+OTDf3Tu5e3tgbKYD1ncq/PVXT2Cfu//64A53/8DdHzj0JHffDSwFWmc4n4RtLnBp4nEZcOgHE+dTfUc/AO5eR7MsOVoq/PVXMfBmXSeZ2ZnARYCW1EomTQO+bWYNgY7Anw459hAw2cwWmNmtZnZWLAnrMRX+QJjZQ4k5019BlCcAAAJPSURBVMWJXf9sZm8B84DxupdCMikxii+kerQ/94hjLwDnAo8ARcBbZvY3bQfk2Kkpa/31F2DwwQ13/6GZNQWWJHYtcvf+sSQTqTYbuBv4JnDmoQfc/WPgKeCpxEXf7sCMTAesrzTir79eAhqa2XWH7GsUVxiRGjwGjHP3tw/daWY9zaxR4vHXgK8DH8aQr97SiL+ecnc3syuAiWZ2M7CV6tUUt8SbTKSau68H7q/h0AXAg2ZWRfXg9FF3X1zDeXKMdOeuiEhgNNUjIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXSZGZXW1mD6bptdYmbqgTyTgVfhGRwKjwS/DMrLGZ/Xeil9E7ZjbMzP7RzP6Y2PdG4g5SgLPM7Hkze8/M7jrkNcrM7O3E8yfUtV8kTrpzVwT6Ah+5+6UAZnYa8BYwzN0Xm9mpwOeJc0uB84EvgEozewDYD0yg+o7THcC8xF3Tb9S0391/n7n/NJG/pRG/CLwN9DazCWb2z0BLYOPBNgHuvsvdqxLnVrj7J+6+F1gBnAP8I7DQ3bcmzvsd1U3FatsvEisVfgmeu68COlP9D8AvgEFJTv/ikMf70V/NcgJS4ZfgJT7oY4+7Pwn8EugK5JvZPyaOf83MkhX4N4AeZtbUzE6iusf8y0n2i8RKoxUR6AD80swOAF8C1wEGPJD4XNjPgX+p7cnuvtHMxgILEs/7b3cvB6htv0ic1J1TRCQwmuoREQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigfn/AUlzhx/5TY8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTY96HPUdcp6"
      },
      "source": [
        "Count Plot Between G3 and extra educational support\n",
        "\n",
        "So, We can see Students not having extra educational support have got good G3  scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "nbmaTCoAtWIp",
        "outputId": "813f64aa-c843-440f-b306-36fdedcc94fc"
      },
      "source": [
        "# count plot on single categorical variable\n",
        "sns.countplot(x ='schoolsup',hue='G3', data = df) \n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roRBsEoCdpLe"
      },
      "source": [
        "Count Plot Between G3 and extra paid classes within the course subject \n",
        "\n",
        "\n",
        "So, Students not going to  extra paid classes within the course subjects have got good score in G3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "VIzFihFdwkwC",
        "outputId": "75fe81bf-3e10-47bd-8aff-1ad219af44b7"
      },
      "source": [
        "# count plot on single categorical variable\n",
        "sns.countplot(x ='paid',hue='G3', data = df) \n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRySSiftd2yK"
      },
      "source": [
        "Count Plot Between G3 and wants to take higher education\n",
        "\n",
        "So,Student pursuing higher education are getting good scores in G3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "5-gmGayOzMTp",
        "outputId": "243418b8-4521-4717-e634-ec30b73d7e2c"
      },
      "source": [
        "# count plot on single categorical variable\n",
        "sns.countplot(x ='higher',hue='G3', data = df) \n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic5PR91AeSP_"
      },
      "source": [
        "Count Plot Between G3 and  Internet access at home\n",
        "\n",
        "So, Student getting internet access at home are getting good scores in G3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "sav34Cr-zP-K",
        "outputId": "880f16ac-94fd-490b-e308-762477bc81e2"
      },
      "source": [
        "# count plot on single categorical variable\n",
        "sns.countplot(x ='internet',hue='G3', data = df) \n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAFDCAYAAAA9PmWPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hV5Zn38e8dE0SYeqAEiIkYrGggASJmRKcdUBlQVFQO6kS0aLBU39oXrYqMzrwVW0fwMHiqVizWUDugcmjEoQoGsPqKVVBQBMEqWEDOgpxEDNzzRzYWMQk7dK+9IM/vc125stdhr/3jusKdJ89+1r3N3RERkXBkxB1ARETSS4VfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCkxl3AJEozZ07t0VmZuZvgCIOvYHObmBBVVXVNaeeeurauMNIw6HCLw1aZmbmb1q1atUuOzt7Y0ZGxiF108ru3btt3bp17VevXv0b4MK480jDcaiNgETqqyg7O3vzoVb0ATIyMjw7O/tzqv9aEUkZFX5p6DIOxaK/RyK7/p9KSukHSiRJy5cvz+zdu3ebvLy8DoWFhe2Ki4sLxo4de/TMmTObFBQUtC8oKGh/8skntx87duzRcWcVqYvm+EWSsHv3bnr37n3i5ZdfvmHKlClLAZYsWdLoueeeO7pPnz6b33vvvYVZWVl88sknWaecckr70tLSTVlZWXHHFqmRCr9IEqZMmfKdrKwsHzp06Lo9+0466aSdt99++zdW23zxxRdmZukPKFIPmuoRScJ77713RMeOHbfXdnzGjBlNTzzxxMLOnTsXjho16hON9uVgpsIvcgCuvPLK1ieffHL7oqKidgBnn332tr/85S/vv/baa4vuvffenO3bt2vYLwctFX6RJHTo0OGLd999t8me7d/97nd/nTVr1pKNGzd+Y7q0c+fOO5o2bbprzpw5R6Q/pUhyVPhFktC7d+8tX375pY0cOTJ7z76tW7dmAHzwwQeNvvrqK6D6Dd+PP/64cdu2bXfGFFVkv/TmrkgSMjIymDJlykc/+clPjnvooYdaNWvWrKpJkya77rjjjhWVlZX/cMEFF+RkZmZ6RkaG33///X/NycmpijuzSG1MH70oDdn8+fOXderUaX3cOf4e8+fPb96pU6f8uHNIw6GpHhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RSI2YcKEI/Pz84tat25ddNttt7WKO4+IbuCSoKx77OlTU3m97OuumFvX8aqqKm688cbWL7300pITTjjhq06dOrXr16/fplNPPXVHKnOI1IdG/CIRmjVrVtPjjz/+y/bt2+9s3Lix9+3b97MJEybog1okVir8IhFavnx5o9zc3K/79uTl5e1cuXJlozgziajwi4gERoVfJELHHXfcN0b4K1as+MZfACJxUOEXiVC3bt22LVu2rPEHH3zQaMeOHTZp0qRm/fr12xR3LgmbVvWIRCgrK4v777//r+eee+5Ju3bt4vLLL19fUlKiFT0SK7VllgZNbZlFvk1TPSIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi0TskksuyW/WrFmntm3bFsadRQR0A5cEZtWjt6e0LXPO/7mrzrbMAGVlZeuHDBmy9uqrr26TytcWOVAa8YtErFevXluzs7Or4s4hsocKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8ItErHfv3m1+8IMfFCxduvTwli1bdhw1alTzuDNJ2LScU4KSzPLLVJsyZcrSdL+mSF004hcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEbLOUXSIDc3t0PTpk13ZWRkkJmZ6QsWLFgUdyYJlwq/BOWdX/dOaVvmU66dkvR9Aa+88sqSnJwcdemU2GmqR0QkMCr8ImnSvXv3toWFhe3uu+8+tWyQWGmqRyQNXnvttQ/atGnz1cqVKzPPPvvskwoLC3f06tVra9y5JEwa8YukQZs2bb4CyM3NrTr//PM3zZ49u2ncmSRcKvwiEdu8eXPGxo0bM/Y8njlz5pEdO3b8Iu5cEi5N9YhEbMWKFZl9+vQ5EWDXrl3Wr1+/Df37998cdy4Jlwq/BKU+yy9TpX379jsXL168MN2vK1IbTfWIiARGhV9EJDCHxFRP8+bNPT8/P+4Ycgi65557WLhw4fFx5/h7bNiwgZKSEo87hxx65s6du97ds/fdf0gU/vz8fObMmRN3DDkELVq0iHbt2sUd4+9iZvr5lwNiZp/UtF9TPSIigVHhFxEJjAq/SBps2rSJ/v37U1BQQLt27Zg9e3bckSRgh8Qcv0iqTB1zXkqvd96gqUmdN2TIEM4991wmTJjAzp072b59e0pziNSHCr9IxD7//HP+9Kc/8dRTTwHQqFEjGjVqFG8oCZqmekQitnTpUrKzs7n66qs55ZRTuOaaa9i2bVvcsSRgKvwiEauqquLtt9/muuuu45133qFp06aMGDEi7lgSMBV+kYjl5eWRl5dHly5dAOjfvz9vv/12zKkkZCr8IhFr1aoVxx13HIsXLwagsrKS9u3bx5xKQqY3d0XS4OGHH2bAgAHs3LmTE044gd/+9rdxRzooXDBxTJ3HX+g3KE1JwqLCL0FJdvllqhUXF6vtghw0NNUjIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBiazwm9nJZjZvr6/NZnaDmTUzs+lm9mHi+zFRZRARkW+LrPC7+2J3L3b3YuBUYDswGRgGVLp7W6AysS3SYC1evJji4uKvv4488kgeeOCBuGNJwNK1jr878JG7f2JmFwFnJvaXA7OAW9OUQwL3ZHnPlF6vbOC0/Z5z8sknM2/ePAB27dpFbm4uffr0SWkOkfpI1xz/vwLjEo9buvuqxOPVQMs0ZRCJXWVlJd/73vc4/vhD+vPf5RAXeeE3s0bAhcBz+x5zdwe8lucNNrM5ZjZn3bp1EacUSY/x48dTWloadwwJXDpG/L2At919TWJ7jZnlACS+r63pSe4+2t1L3L0kOzs7DTFForVz506ef/55LrnkkrijSODSUfhL+ds0D8DzwMDE44FARRoyiMTuj3/8I507d6ZlS81uSrwiLfxm1hToAUzaa/cIoIeZfQj8S2JbpMEbN26cpnnkoBDpqh533wZ8d599G6he5SMSjG3btjF9+nQef/zxuKOIqC2zhCWZ5ZdRaNq0KRs2bIjltUX2pcIvIpE5b/LIOo9n0DxNSWRv6tUjIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXidioUaMoLCykqKiI0tJSduzYEXckCZyWc0pQfvnMOSm93r9f9lKdx1euXMlDDz3EwoULOeKII7j00ksZP348V111VUpziNSHCr9IxKqqqvjiiy/Iyspi+/btHHvssXFHajD6TJxZ5/HJ/c5KU5JDi6Z6RCKUm5vLzTffTOvWrcnJyeGoo46iZ8/UfhiMSH2p8ItEaOPGjVRUVLB06VI+/fRTtm3bxtNPPx13LAmcCr9IhF5++WXatGlDdnY2WVlZ9O3bl9dffz3uWBI4FX6RCLVu3Zo33niD7du34+5UVlbSrl27uGNJ4FT4RSLUpUsX+vfvT+fOnenQoQO7d+9m8ODBcceSwGlVjwRlf8svozB8+HCGDx+e9tcVqY1G/CIigVHhFxEJjAq/iEhgov6w9aPNbIKZfWBmi8zsDDNrZmbTzezDxPdjoswgIiLfFPWI/0HgRXcvADoBi4BhQKW7twUqE9siIpImkRV+MzsK6AqMAXD3ne6+CbgIKE+cVg5cHFUGERH5tihH/G2AdcBvzewdM/uNmTUFWrr7qsQ5q4GWEWYQid2DDz5IUVERhYWFPPDAA3HHEYl0HX8m0Bn4qbv/2cweZJ9pHXd3M/Oanmxmg4HBUH33o0gq9KooTen1/njRuDqPL1iwgCeeeII333yTRo0ace6553LBBRdw4oknpjSHSH1EOeJfAaxw9z8ntidQ/YtgjZnlACS+r63pye4+2t1L3L0kOzs7wpgi0Vm0aBFdunShSZMmZGZm0q1bNyZNmhR3LAlcZIXf3VcDy83s5MSu7sBC4HlgYGLfQKAiqgwicSsqKuLVV19lw4YNbN++nalTp7J8+fK4Y0ngom7Z8FPg92bWCPgYuJrqXzbPmtkg4BPg0ogziMSmXbt23HrrrfTs2ZOmTZtSXFzMYYcdFncsCVykhd/d5wElNRzqHuXrihxMBg0axKBBgwC47bbbyMvLizmRhE5N2kQitnbtWlq0aMFf//pXJk2axBtvvBF3JAmcCr9IxPr168eGDRvIysriV7/6FUcffXTckSRwKvwSlP0tv4zCq6++mvbXFKmLCr+IHLR6T5hY5/FMa5amJA2LunOKiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFIlZWVkaLFi0oKir6et9nn31Gjx49aNu2LT169GDjxo0xJpTQaDmnBOW8ySNTer2pfW7d7zlXXXUV119/PT/84Q+/3jdixAi6d+/OsGHDGDFiBCNGjGDkyNRmE6mNRvwiEevatSvNmn1zvXlFRQUDB1Y3qR04cCB/+MMf4ogmgdKIXyQGa9asIScnB4BWrVqxZs2amBM1TJdNXFLrsWf6nZTGJAcXjfhFYmZmmFncMSQgKvwiMWjZsiWrVlV/9PSqVato0aJFzIkkJCr8IjG48MILKS8vB6C8vJyLLroo5kQSEhV+kYiVlpZyxhlnsHjxYvLy8hgzZgzDhg1j+vTptG3blpdffplhw4bFHVMCojd3JSjJLL9MtXHjam4FXVlZmeYkItU04hcRCUykI34zWwZsAXYBVe5eYmbNgGeAfGAZcKm767ZFEZE0SceI/yx3L3b3PR+6PgyodPe2QGViW0RE0iSOqZ6LgPLE43Lg4hgyiIgEK+rC78A0M5trZoMT+1q6+6rE49VAy4gziIjIXqJe1fMDd19pZi2A6Wb2wd4H3d3NzGt6YuIXxWCA1q1bRxxTRCQckY743X1l4vtaYDJwGrDGzHIAEt/X1vLc0e5e4u4l2dnZUcYUiVRNbZmfe+45CgsLycjIYM6cOTGmkxBFNuI3s6ZAhrtvSTzuCdwJPA8MBEYkvldElUFkXxdMHJPS673Qb9B+z6mpLXNRURGTJk3ixz/+cUrziCQjyqmelsDkRPOpTOC/3f1FM3sLeNbMBgGfAJdGmEEkdl27dmXZsmXf2NeuXbt4wogQYeF394+BTjXs3wB0j+p1RUSkbrpzV0QkMCr8IiKBUeEXEQmMCr9IxGpqyzx58mTy8vKYPXs2559/Puecc07cMSUgasssQUlm+WWq1daWuU+fPmlOIlJNI34RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EUiVlNb5ltuuYWCggI6duxInz592LRpU4wJJTRaxy9B6T1hYkqvN6V/v/2eU1Nb5h49enD33XeTmZnJrbfeyt13383IkSNTmk2kNhrxi0Ssa9euNGvW7Bv7evbsSWZm9bjr9NNPZ8WKFXFEk0Cp8IvE7Mknn6RXr15xx5CAJFX4zawymX0iUj933XUXmZmZDBgwIO4oEpA65/jNrDHQBGhuZscAljh0JJAbcTaRBu2pp57ihRdeoLKyksQn1Ymkxf7e3P0xcANwLDCXvxX+zcAjEeYSadBefPFF7rnnHl555RWaNGkSd5wgjZ60ts7jg/u2SFOS9KtzqsfdH3T3NsDN7n6Cu7dJfHVydxV+kSTU1Jb5+uuvZ8uWLfTo0YPi4mKuvfbauGNKQJJazunuD5vZPwH5ez/H3cfu77lmdhgwB1jp7heYWRtgPPBdqv+KuNLddx5AdpF6S2b5ZarV1JZ50KD0t4cW2SPZN3d/B9wH/AD4x8RXSZKvMQRYtNf2SGCUu58IbAT0P0BEJI2SvYGrBGjv7l6fi5tZHnA+cBfwM6t+B+ts4PLEKeXAHcBj9bmuiIgcuGTX8S8AWh3A9R8AhgK7E9vfBTa5e1ViewVaHSQiklbJjvibAwvN7E3gyz073f3C2p5gZhcAa919rpmdWd9gZjYYGAzQunXr+j5dRERqkWzhv+MArv194EIzOw9oTPXa/weBo80sMzHqzwNW1vRkdx8NjAYoKSmp1xSTiIjULtlVPa/U98Lu/m/AvwEkRvw3u/sAM3sO6E/1yp6BQEV9ry0iIgcu2VU9W8xsc+Jrh5ntMrPNB/iat1L9Ru9fqJ7zH3OA1xE5JNTUlvk//uM/6NixI8XFxfTs2ZNPP/00xoQSmmRH/N/Z8zixMuci4PRkX8TdZwGzEo8/Bk6rT0iRVOkzcWZKrze531n7Paemtsy33HILv/jFLwB46KGHuPPOO/n1r3+d0mwital3d06v9gfgnAjyiDQ4NbVlPvLII79+vG3bNvXqkbRKasRvZn332sygel3/jkgSiQTi9ttvZ+zYsRx11FHMnJnav0RE6pLsiL/3Xl/nAFuonu4RkQN01113sXz5cgYMGMAjj6j1laRPsnP8V0cdRCRUAwYM4LzzzmP48OFxR5FAJLuqJ8/MJpvZ2sTXxEQ7BhE5AB9++OHXjysqKigoKIgxjYQm2Ru4fgv8N3BJYvuKxL4eUYQSaUhKS0uZNWsW69evJy8vj+HDhzN16lQWL15MRkYGxx9/vFb0SFolW/iz3f23e20/ZWY3RBFIJErJLL9MNbVlloNNsm/ubjCzK8zssMTXFcCGKIOJiEg0ki38ZcClwGpgFdUtF66KKJOIiEQo2ameO4GB7r4RwMyaUf3BLGVRBRMRkWgkO+LvuKfoA7j7Z8Ap0UQSEZEoJVv4M8zsmD0biRF/sn8tiIjIQSTZ4n0/MDvRUhmql3XeFU0kERGJUlIjfncfC/QF1iS++rr776IMJtJQ1NSWeY/7778fM2P9+vUxJJNQJT1d4+4LgYURZhGJ3GUTl6T0es/0O2m/59TUlhlg+fLlTJs2TR8tKmlX77bMIlI/NbVlBrjxxhu555571JJZ0k6FXyQGFRUV5Obm0qlTp7ijSIC0MkckzbZv385//ud/Mm3atLijSKA04hdJs48++oilS5fSqVMn8vPzWbFiBZ07d2b16tVxR5NARDbiN7PGwJ+AwxOvM8Hdf25mbYDxVH/Q+lzgSnffGVUOkYNNhw4dWLt27dfb+fn5zJkzh+bNm8eYSkIS5VTPl8DZ7r7VzLKA18zsj8DPgFHuPt7Mfg0MAh6LMIdIrGpqy6zunAe/Gb9fV+fxswdkpylJ6kVW+N3dga2JzazElwNnA5cn9pcDd6DCL2mSzPLLVKupLfPeli1blp4gIgmRzvEnWjjPA9YC04GPgE3uXpU4ZQWQG2UGERH5pkhX9bj7LqDYzI4GJgNJf76cmQ0GBgO6weXvdMHEMbUee6GfphxEQpOWVT3uvgmYCZwBHG1me37h5AEra3nOaHcvcfeS7OxDdy5NRORgE1nhN7PsxEgfMzuC6s/nXUT1L4D+idMGAhVRZRARkW+LcqonByg3s8Oo/gXzrLu/YGYLgfFm9kvgHaD2eQhJynmTR9Z5PAMtExSRv4lyVc+71PBhLe7+MXBaVK8rIiJ10527IhGrqS3zHXfcQW5uLsXFxRQXFzN16tQYE0po1KtHgjJ60tr9n1QPg/u22O85tbVlvvHGG7n55ptTmkckGRrxi0SstrbMInFR4ReJySOPPELHjh0pKytj48aNcceRgKjwi8Tguuuu46OPPmLevHnk5ORw0003xR1JAqLCLxKDli1bcthhh5GRkcGPfvQj3nzzzbgjSUD05q5IDFatWkVOTg4AkydPrvGD2OXg9uEja+o83vb6lmlKUn8q/CIRq6kt86xZs5g3bx5mRn5+Po8//njcMSUgKvwSlGSWX6ZaTW2Z1Y9f4qTCLyK1+uUz59R5/N8veylNSSSV9OauiEhgVPhFRAKjwi8iEhgVfhGRwOjNXRE5YL0qSus8bhSnKYnUh0b8IhGrqS0zwMMPP0xBQQGFhYUMHTo0pnQSIo34JSgzfr8updc7e8D+Pw+6prbMM2fOpKKigvnz53P44Yezdm1q20WL1EUjfpGI1dSW+bHHHmPYsGEcfvjhALRokf4byyRcKvwiMViyZAmvvvoqXbp0oVu3brz11ltxR5KARFb4zew4M5tpZgvN7H0zG5LY38zMppvZh4nvx0SVQeRgVVVVxWeffcYbb7zBvffey6WXXoq7xx1LAhHliL8KuMnd2wOnAz8xs/bAMKDS3dsClYltkaDk5eXRt29fzIzTTjuNjIwM1q9fH3csCURkhd/dV7n724nHW4BFQC5wEVCeOK0cuDiqDCIHq4svvpiZM2cC1dM+O3fupHnz5jGnklCkZVWPmeUDpwB/Blq6+6rEodXAwdu0WiQFamrLXFZWRllZGUVFRTRq1Ijy8nLMLO6oEojIC7+Z/QMwEbjB3Tfv/cPt7m5mNU5smtlgYDBA69ato44pgUhm+WWq1dSWGeDpp59OcxKRapGu6jGzLKqL/u/dfVJi9xozy0kczwFqXMDs7qPdvcTdS7Kz0/+fVUSkoYpyVY8BY4BF7v5fex16HhiYeDwQqIgqg4iIfFuUUz3fB64E3jOzeYl9twEjgGfNbBDwCXBphBlERGQfkRV+d38NqO3dqu5Rva6IiNRNd+6KiARGhV9EJDAq/CIRq6kt82WXXUZxcTHFxcXk5+dTXKy+9ZI+asssdeozcWadxyf3OytNSVLjw0fWpPR6ba/f//2HNbVlfuaZZ75+fNNNN3HUUUelNJdIXVT4RSLWtWtXli1bVuMxd+fZZ59lxowZ6Q0lQdNUj0iMXn31VVq2bEnbtm3jjiIBUeEXidG4ceMoLa37c2tFUk1TPSIxqaqqYtKkScydOzfuKBIYjfhFYvLyyy9TUFBAXl5e3FEkMBrxB673hIl1Hs+0ZnUel/2rqS3zoEGDGD9+vKZ5JBYq/BKUZJZfplptbZmfeuqp9AYRSdBUj4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMFrOeQjoVVH3Wm9DLX0PZmVlZbzwwgu0aNGCBQsWADBv3jyuvfZaduzYQWZmJo8++iinnXZazEkllVb/1/t1Hm/1s8I0Jfk2FX4Jyv7+M9ZXMv95a2rLPHToUH7+85/Tq1cvpk6dytChQ5k1a1ZKs4nUJrKpHjN70szWmtmCvfY1M7PpZvZh4vsxUb2+yMGia9euNGv2zTugzYzNmzcD8Pnnn3PsscfGEU0CFeWI/yngEWDsXvuGAZXuPsLMhiW2b40wg8hB6YEHHuCcc87h5ptvZvfu3bz++utxR5KARDbid/c/AZ/ts/sioDzxuBy4OKrXFzmYPfbYY4waNYrly5czatQoBg0aFHckCUi6V/W0dPdVicergfQ3ThE5CJSXl9O3b18ALrnkEt58882YE0lIYntz193dzLy242Y2GBgM0Lp167TlisMvnzmn7hMaq0NmQ3PsscfyyiuvcOaZZzJjxgx9ApekVboL/xozy3H3VWaWA6yt7UR3Hw2MBigpKan1F4TIwa6mtsxPPPEEQ4YMoaqqisaNGzN69Oi4Y0pA0l34nwcGAiMS3yvS/PoSuDjWTtfWllmfvCVxiazwm9k44EyguZmtAH5OdcF/1swGAZ8Al0b1+pIel01cUufxZ/qdlKYkIpKsyAq/u9d2u2n3qF5TRET2T3fuisTsq7Ub4o4ggVGTNhGRwKjwi4gEJpipnnWPPV3rsezrrkhjkrCMnlTril0ABvdtkaYkUpMny3vWfUJjS08QSSuN+EUiVlZWRosWLSgqKvp63/z58znjjDPo0KEDF19xOZu3bIkxoYQmmBG/CMDahytTer0WP93/IrWa2jJfc8013HfffXTr1o0nHniI+3/1CMOH/VtKs4nURiN+kYjV1JZ5yZIldO3aFYDu3c5k8v9MiSOaBEqFXyQGhYWFVFRU37g+cUoFK1aujDmRhESFXyQGTz75JI8++iinnnoqW7ZupVGjRnFHkoBojl9iNeP36+o8fvaA7DQlSa+CggKmTZsGwPuz/8wfp0+POZGERCN+kRisXVu9zHX37t3cPeq/GDzwqngDSVBU+EUiVlpayhlnnMHixYvJy8tjzJgxjBs3jpNOOomCggJyWrZiYOnlcceUgGiqR4KSzPLLVKutLfOQIUMA9eqR9NOIX0QkMBrxp4Fuiz9wHz6yps7j39m5vu4L9NLYZuqY82o/qAoQJP2vEBEJjAq/NHjuh+5HNh/K2eXgpcIvDVrjxo3ZsGHDIVlA3Z2NW7fQuHHjuKNIA6MZPmnQ8vLyWLFiBevW1X2jWJx2bdla67GsbTs44QenpzGNhCCWwm9m5wIPAocBv3H3EXHkkIYvKyuLNm3axB2jTnV9VgRA1ln/nKYkEoq0F34zOwz4FdADWAG8ZWbPu/vCdGeRhq+uNsxxrOk/EKsevb3O46sz3q37AlkpDCMps78W4VH+fMYxx38a8Bd3/9jddwLjgYtiyCEiEqQ4Cn8usHyv7RWJfSIikgaW7tUOZtYfONfdr0lsXwl0cffr9zlvMDA4sXkysDitQRu25sB+7nwSiYV+NlPreHf/VovbON7cXQkct9d2XmLfN7j7aGB0ukKFxMzmuHtJ3DlE9qWfzfSIY6rnLaCtmbUxs0bAvwLPx5BDRCRIaR/xu3uVmV0PvET1cs4n3f39dOcQEQlVLOv43X0qMDWO1xZAU2hy8NLPZhqk/c1dERGJl3r1iIgERoVfRCQwKvwiIoFR4W/AzCzfzBaZ2RNm9r6ZTTOzI8ys2MzeMLN3zWyymR0Td1YJg5ndaWY37LV9l5kNMbNbzOytxM/k8MSxpmb2P2Y238wWmNll8SVvWFT4G762wK/cvRDYBPQDxgK3untH4D3g5zHmk7A8CfwQwMwyqL6PZzXVP6enAcXAqWbWFTgX+NTdO7l7EfBiPJEbHhX+hm+pu89LPJ4LfA842t1fSewrB7rGkkyC4+7LgA1mdgrQE3gH+Me9Hr8NFFD9i+A9oIeZjTSzf3b3z+NJ3fDog1gavi/3erwLODquICIJvwGuAlpR/RdAd+Bud3983xPNrDNwHvBLM6t09zvTGbSh0og/PHM++0IAAAJzSURBVJ8DG81sz6d7XAm8Usf5Iqk2meppnH+k+g7+l4AyM/sHADPLNbMWZnYssN3dnwbuBTrHFbih0Yg/TAOBX5tZE+Bj4OqY80hA3H2nmc0ENrn7LmCambUDZpsZwFbgCuBE4F4z2w18BVwXV+aGRnfuikhaJd7UfRu4xN0/jDtPiDTVIyJpY2btgb8AlSr68dGIX0QkMBrxi4gERoVfRCQwKvwiIoFR4ZfgmNnrSZxzQ2K5a9RZis3svKhfR2RvKvwSHHf/pyROuwGoV+E3s8MOIE4x1XemiqSNCr8Ex8y2Jr6faWazzGyCmX1gZr+3av8XOBaYmbjRCDPraWazzextM3tur7tMlyV6ybwNXJLYHp447z0zK0ic19TMnjSzN83sHTO7yMwaAXcCl5nZPHWflHRR4ZfQnUL16L49cALwfXd/CPgUOMvdzzKz5sC/A//i7p2BOcDP9rrGBnfv7O7jE9vrE+c9Btyc2Hc7MMPdTwPOoroFQRbw/4Bn3L3Y3Z+J9F8qkqCWDRK6N919BYCZzQPygdf2Oed0qn8x/P9ES4FGwOy9ju9bsCclvs8F+iYe9wQuNLM9vwgaA61TkF+k3lT4JXT7di+t6f+EAdPdvbSWa2yr5Zp7X8+Afu6++BsXNutSv7gifz9N9YjUbAvwncTjN4Dvm9mJ8PV8/Un1vN5LwE8t8SdDoh/9vq8jkhYq/CI1Gw28aGYz3X0d1f3jx5nZu1RP8xTU83q/oHpO/10zez+xDTATaK83dyWd1KtHRCQwGvGLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwPwv8GtXrSHqxFkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKZ91xyyvzmb",
        "outputId": "ad16e18f-b488-4957-910c-c64f0cb24de2"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 649 entries, 0 to 648\n",
            "Data columns (total 33 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   school      649 non-null    object\n",
            " 1   sex         649 non-null    object\n",
            " 2   age         649 non-null    int64 \n",
            " 3   address     649 non-null    object\n",
            " 4   famsize     649 non-null    object\n",
            " 5   Pstatus     649 non-null    object\n",
            " 6   Medu        649 non-null    int64 \n",
            " 7   Fedu        649 non-null    int64 \n",
            " 8   Mjob        649 non-null    object\n",
            " 9   Fjob        649 non-null    object\n",
            " 10  reason      649 non-null    object\n",
            " 11  guardian    649 non-null    object\n",
            " 12  traveltime  649 non-null    int64 \n",
            " 13  studytime   649 non-null    int64 \n",
            " 14  failures    649 non-null    int64 \n",
            " 15  schoolsup   649 non-null    object\n",
            " 16  famsup      649 non-null    object\n",
            " 17  paid        649 non-null    object\n",
            " 18  activities  649 non-null    object\n",
            " 19  nursery     649 non-null    object\n",
            " 20  higher      649 non-null    object\n",
            " 21  internet    649 non-null    object\n",
            " 22  romantic    649 non-null    object\n",
            " 23  famrel      649 non-null    int64 \n",
            " 24  freetime    649 non-null    int64 \n",
            " 25  goout       649 non-null    int64 \n",
            " 26  Dalc        649 non-null    int64 \n",
            " 27  Walc        649 non-null    int64 \n",
            " 28  health      649 non-null    int64 \n",
            " 29  absences    649 non-null    int64 \n",
            " 30  G1          649 non-null    int64 \n",
            " 31  G2          649 non-null    int64 \n",
            " 32  G3          649 non-null    int64 \n",
            "dtypes: int64(16), object(17)\n",
            "memory usage: 167.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t1L54aESEc-"
      },
      "source": [
        "Applying One Hot Encoding  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsTRE-j1zqgK"
      },
      "source": [
        "df3 = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V42U1ngrvXCI"
      },
      "source": [
        "cat=['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMVNnerAy-xC"
      },
      "source": [
        "df3=pd.get_dummies(df3,columns=cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcfbX68_w2Ah",
        "outputId": "7cd1c0ae-41c2-4766-c32a-3563c948b354"
      },
      "source": [
        "df3.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(649, 59)"
            ]
          },
          "metadata": {},
          "execution_count": 464
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "KZ6D2nfeTMPs",
        "outputId": "77d514e5-2c3e-4ce1-a506-0b189317c0ba"
      },
      "source": [
        "X = df3.drop('G3',axis='columns')\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>school_GP</th>\n",
              "      <th>school_MS</th>\n",
              "      <th>sex_F</th>\n",
              "      <th>sex_M</th>\n",
              "      <th>address_R</th>\n",
              "      <th>address_U</th>\n",
              "      <th>famsize_GT3</th>\n",
              "      <th>famsize_LE3</th>\n",
              "      <th>Pstatus_A</th>\n",
              "      <th>Pstatus_T</th>\n",
              "      <th>Mjob_at_home</th>\n",
              "      <th>Mjob_health</th>\n",
              "      <th>Mjob_other</th>\n",
              "      <th>Mjob_services</th>\n",
              "      <th>Mjob_teacher</th>\n",
              "      <th>Fjob_at_home</th>\n",
              "      <th>Fjob_health</th>\n",
              "      <th>Fjob_other</th>\n",
              "      <th>Fjob_services</th>\n",
              "      <th>Fjob_teacher</th>\n",
              "      <th>reason_course</th>\n",
              "      <th>reason_home</th>\n",
              "      <th>reason_other</th>\n",
              "      <th>reason_reputation</th>\n",
              "      <th>guardian_father</th>\n",
              "      <th>guardian_mother</th>\n",
              "      <th>guardian_other</th>\n",
              "      <th>schoolsup_no</th>\n",
              "      <th>schoolsup_yes</th>\n",
              "      <th>famsup_no</th>\n",
              "      <th>famsup_yes</th>\n",
              "      <th>paid_no</th>\n",
              "      <th>paid_yes</th>\n",
              "      <th>activities_no</th>\n",
              "      <th>activities_yes</th>\n",
              "      <th>nursery_no</th>\n",
              "      <th>nursery_yes</th>\n",
              "      <th>higher_no</th>\n",
              "      <th>higher_yes</th>\n",
              "      <th>internet_no</th>\n",
              "      <th>internet_yes</th>\n",
              "      <th>romantic_no</th>\n",
              "      <th>romantic_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>647</th>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>648</th>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>649 rows Ã— 58 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  Medu  Fedu  ...  internet_yes  romantic_no  romantic_yes\n",
              "0     18     4     4  ...             0            1             0\n",
              "1     17     1     1  ...             1            1             0\n",
              "2     15     1     1  ...             1            1             0\n",
              "3     15     4     2  ...             1            0             1\n",
              "4     16     3     3  ...             0            1             0\n",
              "..   ...   ...   ...  ...           ...          ...           ...\n",
              "644   19     2     3  ...             1            1             0\n",
              "645   18     3     1  ...             1            1             0\n",
              "646   18     1     1  ...             0            1             0\n",
              "647   17     3     1  ...             1            1             0\n",
              "648   18     3     2  ...             1            1             0\n",
              "\n",
              "[649 rows x 58 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 465
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBO-HKYwTPbF",
        "outputId": "4197cc4a-6f8b-4917-b60f-5a01ac9ec5ab"
      },
      "source": [
        "Y = df3['G3']\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      11\n",
              "1      11\n",
              "2      12\n",
              "3      14\n",
              "4      13\n",
              "       ..\n",
              "644    10\n",
              "645    16\n",
              "646     9\n",
              "647    10\n",
              "648    11\n",
              "Name: G3, Length: 649, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 466
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa0GonkmngYU"
      },
      "source": [
        "#splitting the data into training and testing sets\n",
        "trainx,testx,trainy,testy=train_test_split(X,Y,test_size=0.2,random_state=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOvXcgdyn-ru"
      },
      "source": [
        "Decision Tree Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG6mvFc3op7z",
        "outputId": "74705cca-038b-46cd-fa75-726b8b807165"
      },
      "source": [
        "d2=DecisionTreeClassifier()\n",
        "d2.fit(trainx,trainy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 470
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4AdJ3adowRr",
        "outputId": "1a03249e-12bd-4b52-8eee-061ab80f2be7"
      },
      "source": [
        "d2.score(testx,testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35384615384615387"
            ]
          },
          "metadata": {},
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPJqGz0fxn7X"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRVxvAJFpUrC",
        "outputId": "57282adb-a322-44bf-b37e-9b25f0c9de87"
      },
      "source": [
        "r2=RandomForestClassifier()\n",
        "r2.fit(trainx,trainy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0E01hRspZZq",
        "outputId": "0899f871-71de-4c4b-8ee1-ade0117820f4"
      },
      "source": [
        "r2.score(testx,testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3923076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA5TJl85uA6v"
      },
      "source": [
        "HyperParameter Tuning\n",
        "\n",
        "Randomized Search CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4W9hDgBt0UU",
        "outputId": "09bb5e6d-af70-4b44-bf82-281749abf552"
      },
      "source": [
        "RandomForestClassifier().get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'class_weight': None,\n",
              " 'criterion': 'gini',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_impurity_split': None,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': None,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLnr2752t8JD",
        "outputId": "56ec72cc-06b4-4d03-a0c8-f4db8722ea91"
      },
      "source": [
        "n_estimators_list =list(range(10,220,50))\n",
        "criterion_list=['gini','entropy']\n",
        "max_depth_list=list(range(5,41,10))\n",
        "max_depth_list.append(None)\n",
        "min_samples_leaf_list=[x/1000 for x in list(range(5,41,10))]\n",
        "min_samples_split_list=[x/1000 for x in list(range(5,41,10))]\n",
        "max_features_list =['sqrt','log2']\n",
        "\n",
        "params_grid = {\n",
        "    'n_estimators': n_estimators_list,\n",
        "    'criterion' : criterion_list,\n",
        "    'max_depth' : max_depth_list,\n",
        "    'min_samples_leaf' : min_samples_leaf_list,\n",
        "    'min_samples_split' : min_samples_split_list,\n",
        "    'max_features' : max_features_list\n",
        "}\n",
        "params_grid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': ['gini', 'entropy'],\n",
              " 'max_depth': [5, 15, 25, 35, None],\n",
              " 'max_features': ['sqrt', 'log2'],\n",
              " 'min_samples_leaf': [0.005, 0.015, 0.025, 0.035],\n",
              " 'min_samples_split': [0.005, 0.015, 0.025, 0.035],\n",
              " 'n_estimators': [10, 60, 110, 160, 210]}"
            ]
          },
          "metadata": {},
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pux0VsWpwSuD"
      },
      "source": [
        "model_rf= RandomizedSearchCV(estimator =RandomForestClassifier(class_weight='balanced'),param_distributions=params_grid,n_iter=50,cv=3,return_train_score=True,verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJLwFSx5xaDb",
        "outputId": "33987915-ea8f-4ffb-da55-9173373bd5bd"
      },
      "source": [
        "model_rf.fit(X,Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=entropy \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=entropy \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=15, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=15, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=15, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=210, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini, total=   0.4s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.025, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.025, max_features=sqrt, max_depth=35, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.025, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.025, max_features=sqrt, max_depth=35, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.025, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.025, max_features=sqrt, max_depth=35, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=210, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=log2, max_depth=35, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.025, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.015, max_features=log2, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=210, min_samples_split=0.005, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.005, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.005, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.005, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.005, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.005, min_samples_leaf=0.005, max_features=log2, max_depth=5, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=log2, max_depth=None, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.025, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=15, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=15, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=15, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=35, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=35, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.025, max_features=log2, max_depth=35, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.005, max_features=log2, max_depth=25, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=60, min_samples_split=0.035, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=gini, total=   0.1s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=210, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.4s\n",
            "[CV] n_estimators=10, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.015, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.035, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=35, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=60, min_samples_split=0.005, min_samples_leaf=0.035, max_features=log2, max_depth=None, criterion=entropy, total=   0.1s\n",
            "[CV] n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.035, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.025, min_samples_leaf=0.015, max_features=sqrt, max_depth=25, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.015, max_features=log2, max_depth=5, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy \n",
            "[CV]  n_estimators=110, min_samples_split=0.025, min_samples_leaf=0.025, max_features=sqrt, max_depth=None, criterion=entropy, total=   0.2s\n",
            "[CV] n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.015, min_samples_leaf=0.035, max_features=sqrt, max_depth=25, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=10, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=10, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=entropy \n",
            "[CV]  n_estimators=10, min_samples_split=0.005, min_samples_leaf=0.005, max_features=sqrt, max_depth=15, criterion=entropy, total=   0.0s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy \n",
            "[CV]  n_estimators=160, min_samples_split=0.005, min_samples_leaf=0.035, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.3s\n",
            "[CV] n_estimators=110, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=5, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=5, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=110, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=5, criterion=gini \n",
            "[CV]  n_estimators=110, min_samples_split=0.015, min_samples_leaf=0.035, max_features=log2, max_depth=5, criterion=gini, total=   0.2s\n",
            "[CV] n_estimators=160, min_samples_split=0.025, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.025, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.025, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.025, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini, total=   0.3s\n",
            "[CV] n_estimators=160, min_samples_split=0.025, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini \n",
            "[CV]  n_estimators=160, min_samples_split=0.025, min_samples_leaf=0.035, max_features=log2, max_depth=15, criterion=gini, total=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   30.2s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight='balanced',\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,...\n",
              "                   iid='deprecated', n_iter=50, n_jobs=None,\n",
              "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
              "                                        'max_depth': [5, 15, 25, 35, None],\n",
              "                                        'max_features': ['sqrt', 'log2'],\n",
              "                                        'min_samples_leaf': [0.005, 0.015,\n",
              "                                                             0.025, 0.035],\n",
              "                                        'min_samples_split': [0.005, 0.015,\n",
              "                                                              0.025, 0.035],\n",
              "                                        'n_estimators': [10, 60, 110, 160,\n",
              "                                                         210]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=True, scoring=None, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbr1skItrKxY",
        "outputId": "a51b3c28-1d1b-4dce-cdeb-453703941943"
      },
      "source": [
        "model_rf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
              "                       criterion='entropy', max_depth=None, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=0.005, min_samples_split=0.015,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=60,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyhbgTTupXOk",
        "outputId": "18023eb0-9dc0-44bf-800a-9669376f385d"
      },
      "source": [
        "r4=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=None, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=0.005, min_samples_split=0.015,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=60,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "r4.fit(trainx,trainy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
              "                       criterion='entropy', max_depth=None, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=0.005, min_samples_split=0.015,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=60,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 448
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YfbRZIcyxC9",
        "outputId": "21cff4d7-fbb3-402e-c733-7addd8dade59"
      },
      "source": [
        "r4.score(testx,testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4461538461538462"
            ]
          },
          "metadata": {},
          "execution_count": 449
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hMZUEfD1JGD",
        "outputId": "a5d0ab19-d470-4bc4-91cb-63ef45077e53"
      },
      "source": [
        "model_rf.predict([[3,4,4,1,1,0,3,2,3,0,0,2,4,0,7,1,0,1,0,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,0,1,0,1,0,0,1,0,1,1,0,1,0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8])"
            ]
          },
          "metadata": {},
          "execution_count": 450
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C2j5NKc2jQX"
      },
      "source": [
        "Grid Search CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CcoPla32a-u",
        "outputId": "95253764-8c92-4917-a401-6f01715a9258"
      },
      "source": [
        "n_estimators_list1 = [130,160,190]\n",
        "criterion_list1=['gini','entropy']\n",
        "max_depth_list1=[35,55]\n",
        "min_samples_leaf_list1=[0.001,0.005]\n",
        "min_samples_split_list1=[0.001,0.005]\n",
        "max_features_list1 =['log2','sqrt']\n",
        "\n",
        "params_grid1 = {\n",
        "    'n_estimators': n_estimators_list1,\n",
        "    'criterion' : criterion_list1,\n",
        "    'max_depth' : max_depth_list1,\n",
        "    'min_samples_leaf' : min_samples_leaf_list1,\n",
        "    'min_samples_split' : min_samples_split_list1,\n",
        "    'max_features' : max_features_list1\n",
        "}\n",
        "params_grid1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': ['gini', 'entropy'],\n",
              " 'max_depth': [35, 55],\n",
              " 'max_features': ['log2', 'sqrt'],\n",
              " 'min_samples_leaf': [0.001, 0.005],\n",
              " 'min_samples_split': [0.001, 0.005],\n",
              " 'n_estimators': [130, 160, 190]}"
            ]
          },
          "metadata": {},
          "execution_count": 475
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tY989iG11L9"
      },
      "source": [
        "mod=GridSearchCV(estimator=RandomForestClassifier(class_weight='balanced'),param_grid=params_grid1,cv=3,return_train_score= True,verbose=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBUK0mizVPsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58abb12b-de01-45da-b494-16f123b30d63"
      },
      "source": [
        "mod.fit(X,Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.290), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.264), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.204), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.258), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.310), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.259), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.281), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.273), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.218), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.295), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.292), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.259), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.281), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.310), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.231), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.272), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.301), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.241), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.988, test=0.290), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.986, test=0.315), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.993, test=0.218), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.986, test=0.258), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.988, test=0.319), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.991, test=0.204), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.995, test=0.290), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.995, test=0.319), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.181), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.991, test=0.267), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.995, test=0.287), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.993, test=0.199), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.991, test=0.295), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.984, test=0.329), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.998, test=0.264), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.988, test=0.267), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.991, test=0.278), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.995, test=0.218), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.318), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.319), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.250), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.318), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.333), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.255), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.350), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.366), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.278), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.323), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.347), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.282), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.364), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.356), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.282), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.318), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.343), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.241), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.991, test=0.350), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.995, test=0.343), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.984, test=0.222), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.988, test=0.323), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.993, test=0.380), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.995, test=0.218), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.991, test=0.309), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.991, test=0.398), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.245), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.988, test=0.286), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.993, test=0.366), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.991, test=0.236), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.984, test=0.318), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.993, test=0.347), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.993, test=0.213), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.988, test=0.295), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.993, test=0.370), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.988, test=0.269), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.272), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.296), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.236), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.300), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.310), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.241), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.304), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.315), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.227), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.272), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.245), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.227), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.281), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.329), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.208), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.300), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.319), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.227), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.993, test=0.253), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.993, test=0.301), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.993, test=0.245), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.995, test=0.300), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.988, test=0.310), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.991, test=0.241), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.991, test=0.281), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.995, test=0.333), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.995, test=0.185), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.991, test=0.258), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.993, test=0.310), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.995, test=0.255), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.986, test=0.313), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.995, test=0.329), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.991, test=0.222), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.993, test=0.258), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.998, test=0.319), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.995, test=0.199), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.327), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.324), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.241), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.295), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.347), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.245), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.318), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.329), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.278), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.346), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.338), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.306), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.313), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.343), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.287), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.332), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.338), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.264), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.984, test=0.300), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.995, test=0.356), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.991, test=0.231), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.993, test=0.309), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.329), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.995, test=0.264), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.986, test=0.336), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.995, test=0.352), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.998, test=0.278), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.995, test=0.323), total=   0.2s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.982, test=0.352), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.995, test=0.241), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.981, test=0.295), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.993, test=0.370), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.991, test=0.208), total=   0.3s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.988, test=0.332), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.995, test=0.338), total=   0.4s\n",
            "[CV] criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=gini, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.988, test=0.329), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.286), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.296), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.282), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.286), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.333), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.259), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.313), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.296), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.287), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.281), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.319), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.287), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.276), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.356), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.319), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.309), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.315), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.319), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.986, test=0.318), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.995, test=0.361), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.991, test=0.278), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.984, test=0.286), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.995, test=0.333), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.991, test=0.255), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.276), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.329), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.991, test=0.255), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.981, test=0.300), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.995, test=0.338), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.988, test=0.264), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.988, test=0.300), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.998, test=0.338), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.995, test=0.273), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.988, test=0.295), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.991, test=0.352), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.988, test=0.269), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.286), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.366), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.310), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.346), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.352), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.389), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.350), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.384), total=   0.6s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.347), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.364), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.361), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.319), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.327), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.366), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.315), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.300), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.384), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.329), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.991, test=0.313), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.991, test=0.361), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.991, test=0.278), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.984, test=0.323), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.998, test=0.370), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.993, test=0.282), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.323), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.389), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.988, test=0.310), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.988, test=0.382), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.991, test=0.380), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.984, test=0.324), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.991, test=0.341), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.993, test=0.361), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.993, test=0.343), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.984, test=0.313), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.993, test=0.366), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=35, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.991, test=0.338), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.304), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.361), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.287), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.286), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.356), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.273), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.327), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.264), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.278), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.327), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.315), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.310), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.304), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.343), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.287), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.304), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.324), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.315), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.988, test=0.267), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.995, test=0.366), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.993, test=0.245), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.991, test=0.332), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.988, test=0.324), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.991, test=0.278), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.313), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.315), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.245), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.981, test=0.323), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.991, test=0.352), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.986, test=0.241), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.988, test=0.300), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.991, test=0.315), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.991, test=0.343), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.993, test=0.300), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.998, test=0.329), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=log2, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.995, test=0.264), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.336), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.347), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=130, score=(train=1.000, test=0.329), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.332), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.343), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=160, score=(train=1.000, test=0.287), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.313), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.366), total=   0.6s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.001, n_estimators=190, score=(train=1.000, test=0.333), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.341), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.324), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=130, score=(train=1.000, test=0.333), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.346), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.370), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=160, score=(train=1.000, test=0.329), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.313), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.375), total=   0.6s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.001, min_samples_split=0.005, n_estimators=190, score=(train=1.000, test=0.356), total=   0.5s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.988, test=0.323), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.995, test=0.366), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=130, score=(train=0.984, test=0.278), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.986, test=0.313), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.995, test=0.407), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=160, score=(train=0.991, test=0.292), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.995, test=0.346), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.993, test=0.384), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.001, n_estimators=190, score=(train=0.991, test=0.282), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.991, test=0.355), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.998, test=0.343), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=130, score=(train=0.991, test=0.329), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.986, test=0.313), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.995, test=0.412), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=160, score=(train=0.991, test=0.310), total=   0.3s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.993, test=0.346), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.995, test=0.370), total=   0.4s\n",
            "[CV] criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190 \n",
            "[CV]  criterion=entropy, max_depth=55, max_features=sqrt, min_samples_leaf=0.005, min_samples_split=0.005, n_estimators=190, score=(train=0.993, test=0.282), total=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 288 out of 288 | elapsed:  1.8min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight='balanced',\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs...\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [35, 55],\n",
              "                         'max_features': ['log2', 'sqrt'],\n",
              "                         'min_samples_leaf': [0.001, 0.005],\n",
              "                         'min_samples_split': [0.001, 0.005],\n",
              "                         'n_estimators': [130, 160, 190]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring=None, verbose=4)"
            ]
          },
          "metadata": {},
          "execution_count": 477
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_q709zFsSMJ",
        "outputId": "15846082-96c0-4e1a-b0d1-83fa51bc263a"
      },
      "source": [
        "mod.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
              "                       criterion='entropy', max_depth=35, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=0.001, min_samples_split=0.001,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=160,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8mfXA5LsYHX",
        "outputId": "ae4bffcb-2c44-435d-e71a-d5e208d13ede"
      },
      "source": [
        "rf2=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=35, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=0.001, min_samples_split=0.001,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=160,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "rf2.fit(trainx,trainy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
              "                       criterion='entropy', max_depth=35, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=0.001, min_samples_split=0.001,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=160,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6e7_Z2K_qRz",
        "outputId": "3713d3d2-7201-4509-b91f-7562ff7f1940"
      },
      "source": [
        "rf2.score(testx,testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4076923076923077"
            ]
          },
          "metadata": {},
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3phLkS18F69",
        "outputId": "9581a63f-93a4-475f-d46d-a340f8591506"
      },
      "source": [
        "mod_fin.predict([[3,4,4,1,1,0,3,2,3,0,0,2,4,0,7,1,0,1,0,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,0,1,0,1,0,0,1,0,1,1,0,1,0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10])"
            ]
          },
          "metadata": {},
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU60tLQD_Kec"
      },
      "source": [
        "Comparitive Analysis of Classification Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZMme8vo_TKc"
      },
      "source": [
        "Decision Tree Classifier - 0.35384615384615387\n",
        "\n",
        "Random Forest Classifier - 0.3923076923076923\n",
        "\n",
        "Applying HyperParameter Tuning for Random Forest Algorithm\n",
        "\n",
        "1) Randomized Search CV - 0.4461538461538462\n",
        "\n",
        "2) Grid Search CV - 0.4076923076923077"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5O3gEE98yvO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}